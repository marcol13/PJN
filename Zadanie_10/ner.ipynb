{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcjJ-YZy5-Pl"
   },
   "source": [
    "# Wykrywanie encji nazwanych z Flair\n",
    "\n",
    "To już ostatnie laboratoria zadaniowe, w związku z tym, jeśli znajdziecie chwilę wolnego czasu, wypełnijcie proszę ankietę: https://docs.google.com/forms/d/1rHPjpL70XdXRD-ILl3AHophPNUk0AhsFus1-mtkUPsI\n",
    "\n",
    "Pozwoli to mi poprawić laboratoria w przyszłości, z góry dziękuję :)\n",
    "\n",
    "# Flair\n",
    "\n",
    "Biblioteka Flair to bardzo popularne narzędzie do tagowania sekwencji. Zaintstalujmy ją"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4inJhzI0wQmM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "     -------------------------------------- 401.9/401.9 KB 1.5 MB/s eta 0:00:00\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Collecting gensim>=3.4.0\n",
      "  Downloading gensim-4.2.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting gdown==4.4.0\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pptree\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.8.0-cp38-cp38-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (0.6.0)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "     ---------------------------------------- 19.7/19.7 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (4.63.0)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "     -------------------------------------- 788.5/788.5 KB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (2.8.1)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.1/53.1 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (2022.3.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (3.4.3)\n",
      "Requirement already satisfied: transformers>=4.0.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (4.19.2)\n",
      "Collecting hyperopt>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-8.13.0-py3-none-any.whl (51 kB)\n",
      "     --------------------------------------- 51.6/51.6 KB 66.2 kB/s eta 0:00:00\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     -------------------------------------- 981.5/981.5 KB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (1.0.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from flair) (1.10.1)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
      "     ---------------------------------------- 46.3/46.3 KB 1.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gdown==4.4.0->flair) (2.25.1)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.2/128.2 KB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gdown==4.4.0->flair) (3.7.0)\n",
      "Requirement already satisfied: six in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gdown==4.4.0->flair) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.22.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "     -------------------------------------- 983.8/983.8 KB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim>=3.4.0->flair) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "     -------------------------------------- 829.2/829.2 KB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.7/199.7 KB 1.1 MB/s eta 0:00:00\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.2.3->flair) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (4.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.26.0->flair) (0.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers>=4.0.0->flair) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers>=4.0.0->flair) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers>=4.0.0->flair) (20.9)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (1.26.4)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: gdown, mpld3, sqlitedict, langdetect, pptree, wikipedia-api, overrides, future\n",
      "  Building wheel for gdown (pyproject.toml): started\n",
      "  Building wheel for gdown (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=dc8b6a1b1a931ec291328e3db77d3c89e92d34147e592902c4aa1030878bee4d\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\7b\\7b\\5d\\656f46cd6889e4c93977be9586901d0adc1271b2d876c84c96\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=eef901c5e12e718f811c5e26b6d8f61be43627fd5758fe6491183931226b7fd0\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\3d\\9f\\9d\\d806a20bd97bc7076d724fa3e69fa5be61836ba16b2ffa6126\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15718 sha256=37d8f09b939cb6199ba67be19f9e06fe55d38569bbaff57d326b4f1827bd2234\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\ee\\0b\\8c\\3cdf3e7eef4161d79c62df5bef35b0614238d0d2bd3051877a\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=fcf751512f40654cfef8224e7d881ccf64cc19782a0fe2e4a130c316ed7f0d8a\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=d0df01a5b7277a12f62fabfb3ca765321fac9a012c5e00a90787d43cc53cfe05\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\e1\\8b\\30\\5b20240d3d13a9dfafb6a6dd49d1b541c86d39812cb3690edf\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13462 sha256=ded8b049ba21251613b10508d627d10c26986daa3e38ce4e5320fbb6289231ad\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\ed\\88\\e3\\da3d4d73cb91d659488cfa25913b84bbc26febec99d257bce9\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10175 sha256=795dd61e3a814e09ae91ed146a7b3da9a4cdb6f85fa4cfbbbfda7acddb667269\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\6a\\4f\\72\\28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=5c716dfb51c716178500d1d31db239821d1dfe3cf6231021873fcc5197fc6b11\n",
      "  Stored in directory: c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\8e\\70\\28\\3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built gdown mpld3 sqlitedict langdetect pptree wikipedia-api overrides future\n",
      "Installing collected packages: tabulate, sqlitedict, sentencepiece, py4j, pptree, overrides, mpld3, janome, soupsieve, segtok, PySocks, more-itertools, lxml, langdetect, importlib-metadata, future, ftfy, deprecated, Cython, conllu, cloudpickle, wikipedia-api, konoha, hyperopt, gensim, beautifulsoup4, gdown, bpemb, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.2\n",
      "    Uninstalling importlib-metadata-4.11.2:\n",
      "      Successfully uninstalled importlib-metadata-4.11.2\n",
      "Successfully installed Cython-0.29.28 PySocks-1.7.1 beautifulsoup4-4.11.1 bpemb-0.3.3 cloudpickle-2.1.0 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 future-0.18.2 gdown-4.4.0 gensim-4.2.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 lxml-4.8.0 more-itertools-8.13.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 segtok-1.5.11 sentencepiece-0.1.95 soupsieve-2.3.2.post1 sqlitedict-2.0.0 tabulate-0.8.9 wikipedia-api-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0-maEaJD0Ojj"
   },
   "outputs": [],
   "source": [
    "# OPCJONALNE WSPARCIE DLA KART GRAFICZNYCH\n",
    "# W colabie możemy trenować z wykorzystaniem karty graficznej, dzięki temu trening działa dużo szybciej\n",
    "# Aby włączyć wsparcie dla karty graficznej musimy:\n",
    "# 1. w menu 'srodowisko wykonawcze' wybrać `zmien typ srodowiska wykonawczego` i tam `akcelerator sprzętowy` = GPU\n",
    "# 2. odkomentować linijki poniżej\n",
    "import flair, torch\n",
    "flair.device = torch.device('cuda:0') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyApRy6G7YQk"
   },
   "source": [
    "# Ładowanie zbioru danych i słownika z etykietami.\n",
    "\n",
    "**Zadanie1: (1 punkt):** Stwórz słownik etykiet z wczytanego korpusu korzystając z funkcji `make_label_dictionary()`. W naszym zbiorze, etykiety do wykrycia występują w kolumnie `ner`, której identyfikator został zapisany w linijce 6. Tutorial: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md może okazać się pomocny.\n",
    "\n",
    "Efektem działania powinna być lista etykiet np: \n",
    "`Dictionary with 20 tags: <unk>, Variable, Class, Application, User_Interface_Element, Code_Block, Language, Function, Data_Structure, Library, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eK84adKF6GLr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:55:55,956 File train has 741 questions and 897 answers.\n",
      "2022-05-28 11:55:55,979 File test has 249 questions and 315 answers.\n",
      "2022-05-28 11:55:56,000 File dev has 247 questions and 289 answers.\n",
      "2022-05-28 11:55:56,001 Reading data from C:\\Users\\Marcin\\.flair\\datasets\\ner_english_stackoverflow\n",
      "2022-05-28 11:55:56,002 Train: C:\\Users\\Marcin\\.flair\\datasets\\ner_english_stackoverflow\\train.txt\n",
      "2022-05-28 11:55:56,003 Dev: C:\\Users\\Marcin\\.flair\\datasets\\ner_english_stackoverflow\\dev.txt\n",
      "2022-05-28 11:55:56,004 Test: C:\\Users\\Marcin\\.flair\\datasets\\ner_english_stackoverflow\\test.txt\n",
      "2022-05-28 11:56:01,665 Filtering empty sentences\n",
      "2022-05-28 11:56:01,683 Corpus: 3705 train + 1174 dev + 1243 test sentences\n",
      "2022-05-28 11:56:01,684 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3705it [00:00, 112574.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:56:01,722 Dictionary created for label 'ner' with 20 values: Application (seen 539 times), Class (seen 535 times), Variable (seen 449 times), User_Interface_Element (seen 371 times), Code_Block (seen 362 times), Language (seen 310 times), Library (seen 298 times), Function (seen 279 times), Data_Structure (seen 233 times), Data_Type (seen 174 times), File_Type (seen 167 times), File_Name (seen 135 times), Version (seen 113 times), HTML_XML_Tag (seen 93 times), Device (seen 76 times), Operating_System (seen 67 times), Website (seen 37 times), User_Name (seen 36 times), Algorithm (seen 18 times)\n",
      "\n",
      "\n",
      "Etykiety do wykrycia\n",
      "Dictionary with 20 tags: <unk>, Application, Class, Variable, User_Interface_Element, Code_Block, Language, Library, Function, Data_Structure, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.datasets import NER_ENGLISH_STACKOVERFLOW    # zbiór otagowanych postów na Stacku\n",
    "\n",
    "corpus = NER_ENGLISH_STACKOVERFLOW().downsample(0.4)   # pobieramy korpus i zmniejszamy jego wielkość\n",
    "corpus.filter_empty_sentences()                         # usuwamy puste zdania\n",
    "\n",
    "label_type = 'ner'   # identyfikator pod którym możemy dostać typy etykiet\n",
    "label_dict = corpus.make_label_dictionary(label_type)    # TODO\n",
    "print('\\n\\nEtykiety do wykrycia')\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlz60uuR83oR"
   },
   "source": [
    "# Embeddingi\n",
    "\n",
    "W narzędziu Flair możemy bardzo prosto składać ze sobą różne embeddingi. \n",
    "\n",
    "**Zad2 (2 punkty):** Zapoznaj się z działaniem `StackedEmbeddings` opisanego w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md i zbuduj embeddingi zawierające reprezentacje pochodzące zarówno z Glove jak i Flairowe, oparte na `news-forward`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yzCwq37iwFo4"
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "\n",
    "embeddings = StackedEmbeddings([glove_embedding, flair_embedding_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"The\"\n",
      "tensor([-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -4.4014e-04,\n",
      "        -3.9301e-02,  1.0601e-02])\n",
      "Token[1]: \"grass\"\n",
      "tensor([-8.1353e-01,  9.4042e-01, -2.4048e-01,  ..., -3.7749e-04,\n",
      "        -2.3563e-02,  1.1700e-02])\n",
      "Token[2]: \"is\"\n",
      "tensor([-0.5426,  0.4148,  1.0322,  ..., -0.0061,  0.0112,  0.0100])\n",
      "Token[3]: \"green\"\n",
      "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0026, -0.0118,  0.0455])\n",
      "Token[4]: \".\"\n",
      "tensor([-3.3979e-01,  2.0941e-01,  4.6348e-01,  ..., -2.3405e-04,\n",
      "         3.8688e-03,  5.7725e-03])\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "embeddings.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wxgw7Uc91e3"
   },
   "source": [
    "# Tagger i trainer\n",
    "\n",
    "**Zadanie 3 (2 punkty)** Bazując na treściach opisanych w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md przygotuj obiekt `SequenceTagger`, którego rozmiar wartswy ukrytej wyniesie 256. Do obiektu tego przekażemy stworzone wcześniej embeddingi, słownik `label_dict` i nazwę kolumny z etykietą ze zmiennej `label_type`. Ustawmy `use_crf` na True.\n",
    "\n",
    "Przygotuj obiekt `ModelTrainer`, który przyjmie zarówno nasz korpus jak i stworzony przed chwilą `SequenceTagger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZqglzMPP92Fq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:56:19,055 SequenceTagger predicts: Dictionary with 77 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n",
      "2022-05-28 11:56:19,173 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,174 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings(\n",
      "      'glove'\n",
      "      (embedding): Embedding(400001, 100)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2148, out_features=2148, bias=True)\n",
      "  (rnn): LSTM(2148, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=79, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-05-28 11:56:19,175 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,177 Corpus: \"Corpus: 3705 train + 1174 dev + 1243 test sentences\"\n",
      "2022-05-28 11:56:19,178 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,179 Parameters:\n",
      "2022-05-28 11:56:19,179  - learning_rate: \"0.100000\"\n",
      "2022-05-28 11:56:19,180  - mini_batch_size: \"32\"\n",
      "2022-05-28 11:56:19,182  - patience: \"3\"\n",
      "2022-05-28 11:56:19,184  - anneal_factor: \"0.5\"\n",
      "2022-05-28 11:56:19,186  - max_epochs: \"5\"\n",
      "2022-05-28 11:56:19,187  - shuffle: \"True\"\n",
      "2022-05-28 11:56:19,188  - train_with_dev: \"False\"\n",
      "2022-05-28 11:56:19,189  - batch_growth_annealing: \"False\"\n",
      "2022-05-28 11:56:19,190 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,191 Model training base path: \"resources\\taggers\\example-upos\"\n",
      "2022-05-28 11:56:19,191 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,193 Device: cuda:0\n",
      "2022-05-28 11:56:19,195 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:56:19,196 Embeddings storage mode: cpu\n",
      "2022-05-28 11:56:19,196 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marcin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\flair\\trainers\\trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:56:28,276 epoch 1 - iter 11/116 - loss 1.78870488 - samples/sec: 38.78 - lr: 0.100000\n",
      "2022-05-28 11:56:35,922 epoch 1 - iter 22/116 - loss 1.28483405 - samples/sec: 46.05 - lr: 0.100000\n",
      "2022-05-28 11:56:43,965 epoch 1 - iter 33/116 - loss 1.08328164 - samples/sec: 43.77 - lr: 0.100000\n",
      "2022-05-28 11:56:52,153 epoch 1 - iter 44/116 - loss 0.97266513 - samples/sec: 43.01 - lr: 0.100000\n",
      "2022-05-28 11:57:00,297 epoch 1 - iter 55/116 - loss 0.87712983 - samples/sec: 43.23 - lr: 0.100000\n",
      "2022-05-28 11:57:08,086 epoch 1 - iter 66/116 - loss 0.82388234 - samples/sec: 45.21 - lr: 0.100000\n",
      "2022-05-28 11:57:18,208 epoch 1 - iter 77/116 - loss 0.80199892 - samples/sec: 34.79 - lr: 0.100000\n",
      "2022-05-28 11:57:26,178 epoch 1 - iter 88/116 - loss 0.77496190 - samples/sec: 44.18 - lr: 0.100000\n",
      "2022-05-28 11:57:34,734 epoch 1 - iter 99/116 - loss 0.74398487 - samples/sec: 41.15 - lr: 0.100000\n",
      "2022-05-28 11:57:42,557 epoch 1 - iter 110/116 - loss 0.72377483 - samples/sec: 45.01 - lr: 0.100000\n",
      "2022-05-28 11:57:46,873 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:57:46,874 EPOCH 1 done: loss 0.7109 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:28<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:58:14,903 Evaluating as a multi-label problem: False\n",
      "2022-05-28 11:58:14,920 DEV : loss 0.4681435823440552 - f1-score (micro avg)  0.0151\n",
      "2022-05-28 11:58:14,973 BAD EPOCHS (no improvement): 0\n",
      "2022-05-28 11:58:14,975 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:58:16,122 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:58:19,620 epoch 2 - iter 11/116 - loss 0.48745216 - samples/sec: 100.69 - lr: 0.100000\n",
      "2022-05-28 11:58:22,880 epoch 2 - iter 22/116 - loss 0.48020903 - samples/sec: 108.08 - lr: 0.100000\n",
      "2022-05-28 11:58:25,827 epoch 2 - iter 33/116 - loss 0.48686587 - samples/sec: 119.48 - lr: 0.100000\n",
      "2022-05-28 11:58:29,230 epoch 2 - iter 44/116 - loss 0.48008588 - samples/sec: 103.57 - lr: 0.100000\n",
      "2022-05-28 11:58:32,450 epoch 2 - iter 55/116 - loss 0.46988381 - samples/sec: 109.46 - lr: 0.100000\n",
      "2022-05-28 11:58:36,203 epoch 2 - iter 66/116 - loss 0.46699085 - samples/sec: 93.92 - lr: 0.100000\n",
      "2022-05-28 11:58:39,313 epoch 2 - iter 77/116 - loss 0.46316277 - samples/sec: 113.20 - lr: 0.100000\n",
      "2022-05-28 11:58:42,792 epoch 2 - iter 88/116 - loss 0.47086106 - samples/sec: 101.31 - lr: 0.100000\n",
      "2022-05-28 11:58:45,929 epoch 2 - iter 99/116 - loss 0.46777103 - samples/sec: 112.22 - lr: 0.100000\n",
      "2022-05-28 11:58:48,799 epoch 2 - iter 110/116 - loss 0.46763060 - samples/sec: 122.83 - lr: 0.100000\n",
      "2022-05-28 11:58:50,541 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:58:50,542 EPOCH 2 done: loss 0.4678 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:11<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:59:02,540 Evaluating as a multi-label problem: False\n",
      "2022-05-28 11:59:02,560 DEV : loss 0.3977285921573639 - f1-score (micro avg)  0.1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:59:02,612 BAD EPOCHS (no improvement): 0\n",
      "2022-05-28 11:59:02,614 saving best model\n",
      "2022-05-28 11:59:04,102 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:59:07,790 epoch 3 - iter 11/116 - loss 0.41310685 - samples/sec: 95.52 - lr: 0.100000\n",
      "2022-05-28 11:59:11,510 epoch 3 - iter 22/116 - loss 0.41252842 - samples/sec: 94.68 - lr: 0.100000\n",
      "2022-05-28 11:59:14,490 epoch 3 - iter 33/116 - loss 0.42075050 - samples/sec: 118.26 - lr: 0.100000\n",
      "2022-05-28 11:59:17,530 epoch 3 - iter 44/116 - loss 0.41469776 - samples/sec: 115.92 - lr: 0.100000\n",
      "2022-05-28 11:59:20,832 epoch 3 - iter 55/116 - loss 0.40981681 - samples/sec: 106.64 - lr: 0.100000\n",
      "2022-05-28 11:59:24,471 epoch 3 - iter 66/116 - loss 0.40964201 - samples/sec: 96.83 - lr: 0.100000\n",
      "2022-05-28 11:59:27,689 epoch 3 - iter 77/116 - loss 0.41219555 - samples/sec: 109.50 - lr: 0.100000\n",
      "2022-05-28 11:59:30,894 epoch 3 - iter 88/116 - loss 0.41558619 - samples/sec: 109.89 - lr: 0.100000\n",
      "2022-05-28 11:59:34,733 epoch 3 - iter 99/116 - loss 0.40912494 - samples/sec: 91.73 - lr: 0.100000\n",
      "2022-05-28 11:59:37,689 epoch 3 - iter 110/116 - loss 0.40555475 - samples/sec: 119.21 - lr: 0.100000\n",
      "2022-05-28 11:59:39,355 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:59:39,357 EPOCH 3 done: loss 0.4070 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:13<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:59:52,611 Evaluating as a multi-label problem: False\n",
      "2022-05-28 11:59:52,632 DEV : loss 0.3511420786380768 - f1-score (micro avg)  0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 11:59:52,688 BAD EPOCHS (no improvement): 0\n",
      "2022-05-28 11:59:52,689 saving best model\n",
      "2022-05-28 11:59:54,118 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 11:59:57,121 epoch 4 - iter 11/116 - loss 0.33322562 - samples/sec: 117.29 - lr: 0.100000\n",
      "2022-05-28 12:00:01,733 epoch 4 - iter 22/116 - loss 0.34415696 - samples/sec: 76.35 - lr: 0.100000\n",
      "2022-05-28 12:00:04,855 epoch 4 - iter 33/116 - loss 0.35016192 - samples/sec: 112.79 - lr: 0.100000\n",
      "2022-05-28 12:00:08,427 epoch 4 - iter 44/116 - loss 0.36029312 - samples/sec: 98.62 - lr: 0.100000\n",
      "2022-05-28 12:00:11,967 epoch 4 - iter 55/116 - loss 0.37814336 - samples/sec: 99.49 - lr: 0.100000\n",
      "2022-05-28 12:00:14,993 epoch 4 - iter 66/116 - loss 0.38055581 - samples/sec: 116.45 - lr: 0.100000\n",
      "2022-05-28 12:00:18,138 epoch 4 - iter 77/116 - loss 0.37585109 - samples/sec: 111.94 - lr: 0.100000\n",
      "2022-05-28 12:00:21,281 epoch 4 - iter 88/116 - loss 0.37605130 - samples/sec: 112.03 - lr: 0.100000\n",
      "2022-05-28 12:00:24,992 epoch 4 - iter 99/116 - loss 0.37527030 - samples/sec: 94.92 - lr: 0.100000\n",
      "2022-05-28 12:00:28,024 epoch 4 - iter 110/116 - loss 0.37549487 - samples/sec: 116.21 - lr: 0.100000\n",
      "2022-05-28 12:00:29,577 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 12:00:29,578 EPOCH 4 done: loss 0.3734 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:12<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:00:42,589 Evaluating as a multi-label problem: False\n",
      "2022-05-28 12:00:42,609 DEV : loss 0.3319988250732422 - f1-score (micro avg)  0.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:00:42,661 BAD EPOCHS (no improvement): 0\n",
      "2022-05-28 12:00:42,663 saving best model\n",
      "2022-05-28 12:00:58,276 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 12:01:01,341 epoch 5 - iter 11/116 - loss 0.34956198 - samples/sec: 114.90 - lr: 0.100000\n",
      "2022-05-28 12:01:04,314 epoch 5 - iter 22/116 - loss 0.34039353 - samples/sec: 118.52 - lr: 0.100000\n",
      "2022-05-28 12:01:08,102 epoch 5 - iter 33/116 - loss 0.34577435 - samples/sec: 93.00 - lr: 0.100000\n",
      "2022-05-28 12:01:11,910 epoch 5 - iter 44/116 - loss 0.34400215 - samples/sec: 92.50 - lr: 0.100000\n",
      "2022-05-28 12:01:15,498 epoch 5 - iter 55/116 - loss 0.34243298 - samples/sec: 98.19 - lr: 0.100000\n",
      "2022-05-28 12:01:19,137 epoch 5 - iter 66/116 - loss 0.34139775 - samples/sec: 96.82 - lr: 0.100000\n",
      "2022-05-28 12:01:21,983 epoch 5 - iter 77/116 - loss 0.33955204 - samples/sec: 123.74 - lr: 0.100000\n",
      "2022-05-28 12:01:25,104 epoch 5 - iter 88/116 - loss 0.34050428 - samples/sec: 112.85 - lr: 0.100000\n",
      "2022-05-28 12:01:28,359 epoch 5 - iter 99/116 - loss 0.33980750 - samples/sec: 108.21 - lr: 0.100000\n",
      "2022-05-28 12:01:31,403 epoch 5 - iter 110/116 - loss 0.34268343 - samples/sec: 115.71 - lr: 0.100000\n",
      "2022-05-28 12:01:32,968 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 12:01:32,969 EPOCH 5 done: loss 0.3443 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [00:10<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:01:43,881 Evaluating as a multi-label problem: False\n",
      "2022-05-28 12:01:43,901 DEV : loss 0.30565327405929565 - f1-score (micro avg)  0.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:01:43,956 BAD EPOCHS (no improvement): 0\n",
      "2022-05-28 12:01:43,957 saving best model\n",
      "2022-05-28 12:01:54,475 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 12:01:54,477 loading file resources\\taggers\\example-upos\\best-model.pt\n",
      "2022-05-28 12:01:55,135 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [00:24<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:02:19,748 Evaluating as a multi-label problem: False\n",
      "2022-05-28 12:02:19,768 0.465\t0.2364\t0.3135\t0.2137\n",
      "2022-05-28 12:02:19,770 \n",
      "Results:\n",
      "- F-score (micro) 0.3135\n",
      "- F-score (macro) 0.2488\n",
      "- Accuracy 0.2137\n",
      "\n",
      "By class:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Class     0.4158    0.4158    0.4158       190\n",
      "           Application     0.3224    0.2934    0.3072       167\n",
      "              Variable     0.3333    0.0449    0.0791       156\n",
      "            Code_Block     0.2564    0.0752    0.1163       133\n",
      "               Library     0.4808    0.2294    0.3106       109\n",
      "              Language     0.5366    0.5946    0.5641        74\n",
      "User_Interface_Element     0.7000    0.1148    0.1972       122\n",
      "        Data_Structure     0.7755    0.4270    0.5507        89\n",
      "              Function     0.4444    0.0777    0.1322       103\n",
      "             File_Name     0.5333    0.2133    0.3048        75\n",
      "             File_Type     0.5556    0.3261    0.4110        46\n",
      "               Version     0.6316    0.2727    0.3810        44\n",
      "             Data_Type     0.8889    0.4571    0.6038        35\n",
      "      Operating_System     0.5000    0.2727    0.3529        22\n",
      "          HTML_XML_Tag     0.0000    0.0000    0.0000        27\n",
      "                Device     0.0000    0.0000    0.0000        22\n",
      "               Website     0.0000    0.0000    0.0000         9\n",
      "             User_Name     0.0000    0.0000    0.0000         8\n",
      "             Algorithm     0.0000    0.0000    0.0000         3\n",
      "\n",
      "             micro avg     0.4650    0.2364    0.3135      1434\n",
      "             macro avg     0.3881    0.2008    0.2488      1434\n",
      "          weighted avg     0.4510    0.2364    0.2844      1434\n",
      "\n",
      "2022-05-28 12:02:19,771 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-28 12:02:19,774 loading file resources/taggers/example-upos/final-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 12:02:20,345 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Language, B-Language, E-Language, I-Language, S-Library, B-Library, E-Library, I-Library, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True)\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#stworzony trainer możemy zacząć trenować!\n",
    "trainer.train('resources/taggers/example-upos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=5)\n",
    "\n",
    "# a kiedy wytrenujemy, wczytujemy najlepszy model.\n",
    "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxrd6m0H_-SJ"
   },
   "source": [
    "# Predykcja z udziałem modelu\n",
    "\n",
    "Jeśli model został wytrenowany, poniżej znajdziemy fragment kodu, który może wykryć encje w zdaniach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Koq76zqawM3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"huge files can be opened from Python 3 .\" → [\"Python\"/Language]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Jeśli nasz model się wyuczył, powinien wykryć Python jako język.\n",
    "# Uwaga, ponieważ pracujemy na niewielkim podzbiorze zbioru danych (downsample(0.1) próbkuje 10%), \n",
    "# otrzymywane wyniki mogą być kiepskiej jakości, najlepiej zwiększyść ilość danych \n",
    "# jeśli pracujemy w domu.\n",
    "sentence = Sentence('huge files can be opened from Python 3.')   # stwórz obiekt zdania\n",
    "model.predict(sentence)                                         # wykryj encje nazwane\n",
    "print(sentence.to_tagged_string())                              # wyświetl zdanie i wykryte w nim encje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
